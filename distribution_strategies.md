# Distribution Strategies

## General Load Balancing

### Power of Two Choices (PoTC)

Select two bins u.a.r and later assign the message to the least loaded.
The load is solely based on the number of messages.
Each key might be assigned to any of the workers.

> This algorithm is not suitable for stateful operations
> Use PKG instead

## General Streaming Load Balancing

### [Partial Key Grouping (PKG)](../papers/PartialKeyGrouping.pdf)

PoTC adapted to distributed stream processing with **stateful operations** with keys.

- **Key splitting**. Choice based on load for each message.
- **Local load estimation**. There are _n_ sources but we only need to keep local load information of each source (not global). Proof on paper.

```
P_t(k) = {arg\ max}_i \{ L_i(t) : \mathcal{H}_1(k) = i \lor \mathcal{H}_2(k) = i \}
```

### [Improvement on PKG](../papers/WhenTwoChoicesAreNotEnoughBalancingAtScaleInDistributedStreamProcessing.pdf)

### [Consistent Grouping](../papers/LoadBalancingForSkewedStreamsOnHeterogeneousClusters.pdf)

## CER Load Balancing

### Maximal Matches Enumeration

> In order to implement this strategy, you must signal CORE to compute only the maximal matches.
> This can be achieved by replacing `SELECT *` by `SELECT MAX *`

#### Enumeration on Engine

> Do not implement.
> CORE does this by default in a more efficient way.

```
Input:
  Query: AB+C+D
  Stream: A1 B1 B2 C1 C2 C3 D1
  Maximal Match: A1 B1 B2 C1 C2 C3 D1

1. Generate the power sets of each kleene star (remove empty set)
Powerset of A: {{A1}}
Powerset of B: {{B1}, {B2}, {B1, B2}}
Powerset of C: {{C1}, {C2}, {C3}, {C1,C2}, {C1, C3}, {C1, C2, C3}}
Powerset of D: {{D1}}

2. Use guava's cartesian product https://guava.dev/releases/snapshot/api/docs/com/google/common/collect/Sets.html#cartesianProduct-java.util.List
    to generate all possible combinations of the different kleene powersets.
[A1, B1, C1, D1]
[A1, B1, C2, D1]
[A1, B1, C3, D1]
[A1, B1, C1, C2, D1]
[A1, B1, C1, C3, D1]
[A1, B1, C1, C2, C3, D1]
[A1, B2, C1, D1]
...

3. For each one, create a Match.
4. Distribute the matches taking into account the load.
```

#### Enumeration on workers

The key idea here is that enumerating is expensive, so we want to delegate it to the workers.

```
1. For all maximal matches:
    1.1. Group by event type: {{A1}, {B1 B2}, {C1 C2 C3}, {D1}}
    1.2. Subsets sizes: {{1}, {1,2}, {1,2,3}, {1}}
    1.3. Cartesian product of subsets sizes to generate all configurations:
    1.4. Match configurations and their corresponding maximal matches.
2. Distribute all tuples <maximal matches, configuration> using a load-balancing algorithm.

Works should enumerate all matches of the given maximal match filtered by configuration's sizes  and process the SOL-predicates. 
```

Configurations and load-balancing must be computed efficiently. 
Otherwise, the cost of these centralized tasks would overweight the distribution gains.

Notice, this approach has a **fatal problem** which is that the **generated submatches are not unique** (see "Unique Maximal Matches Enumeration" for more information).

### Maximal Matches Disjoint Enumeration

This is an adaptation of _"Maximal Matches Enumeration"_ that guarantees that generated submatches are not repeated.

You need to make the following observations of "Maximal Matches Enumeration":
1. The algorithm produces disjoint submatches given a maximal match.
2. The algorithm produces non-disjoint submatches given multiple maximal matches.

But (2) can be analyzed further:
1. Disjoint configurations produce disjoint submatches.
2. Non-disjoint configurations produce non-disjoint submatches.

From previous observations we can conclude that repeated submatches are only generated by applying the same configuration to different maximal matches.

We propose the following algorithm:
1. (1.1),(1.2),(1.3) and (1.4) as in "Maximal Matches Enumeration"
2. Group pairs from (1) by configuration: <configuration, {maximal matches}>
3. Distribute pairs from (2). Each configuration is assigned to a single worker.
4. Enumerate submatches at worker. The output must be a set since enumeration may generated repeated outputs.

Uniqueness of submatches is guaranteed by (3) and (4). 
(3) guarantees that the output of each worker is disjoint wrt the others. 
(4) guarantees that the output of a worker is disjoint.

The complexity of the algorithm remains the same if we accomplish linear time enumeration in each worker (this is the tricky part).
