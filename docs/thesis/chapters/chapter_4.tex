\chapter{Lore Ipsum}\label{chapter}

% \section{Distributed enumeration of complex events}
% \label{sec:distributed_enumeration_of_the_complex_events}

In this section, we present two distributed enumeration algorithms: (1) \acrfull{mmde}, and (2) \acrfull{dte}.

CORE's evaluation algorithm guarantees, under data complexity, constant time per event and constant-delay enumeration of the output. However, under the default \emph{skip-till-any-match} \cite{skip-till-any-match} policy in CORE, non-contiguous sequencing and iteration can cause the amount of complex events to grow exponentially in the size of the stream \cite{formal-framework-cer}. The evaluation algorithms needs to materialize the set of partial matches each time an enumeration is required; therefore, in the worst case, enumerating all complex events generated by an event is exponential in the length of the stream. In order to deal with the exponential complexity of materializing and enumerating complex events in the evaluation algorithm, we propose to employ distributed execution of the process \cite{distributed-computing-book}.

% \subsection{Maximal Matches Disjoint Enumeration}\label{subsec:mmde}

We propose a novel enumeration algorithm called \acrfull{mmde}

Talk about the algorithm: build on top of CORE, in the compilation of the query,...

Define: match, maximal match, configuration, ... (get inspire by CORE's paper)

Define the operations on the tree.

Define group by (maybe, it would be easier to define a new concept)

\begin{algorithm}[H]
  \DontPrintSemicolon
  \SetAlgoNoEnd % don't print end
  \SetAlgoNoLine % no vertical lines
  \LinesNumbered
  \SetKwProg{Procedure}{procedure}{}{}
  \SetKwFunction{MMDE}{\textsc{MaximalMatchesDisjointEnumeration}}
  \SetKwFunction{Enumerate}{\textsc{Enumerate}}

  \Procedure{\MMDE{$M$, $W$}}{
    \KwIn{A set of maximal matches $M := \{M_{1}, \ldots, M_{n}\}$ \newline
      and a set of workers $W := \{w_{1},\ldots, w_{m}\}$.
    }
    \KwResult{Enumerates all \emph{submatches} $\subseteq M$ without repetitions.}
    $C \leftarrow \emptyset$\;
    \ForEach{$M_{i} \in M$}{
        $C \leftarrow C \cup \textsc{Configurations}(M_{i}).map(\lambda c \to ( c, M_{i} ))$\;
    }
    $D \leftarrow C.groupBy(\lambda (c, \_ ) \to c)$\;
    $\textsc{Distribute}(W, D)$
  }
  \;
\caption{Non-repeated enumeration of a set of maximal matches.}
\label{algo:mmde}
\end{algorithm}

% This procedure enumerates all submatches of M without repetitions.
% It stills enumerates all submatches but only outputs non-repeated.
% It efficiently detects repetitions by constructing an n-ary tree of complex events.
% The complexity is still exponential w.r.t. the size of the largest iteration.
% The exponential time enumeration must be repeated a constant factor of times.
\begin{algorithm}[H]
  \DontPrintSemicolon
  \SetAlgoNoEnd % don't print end
  \SetAlgoNoLine % no vertical lines
  \LinesNumbered
  \SetKwProg{Procedure}{procedure}{}{}
  \SetKwFunction{Enumerate}{\textsc{Enumerate}}
  \SetKwFunction{Enumeratee}{\textsc{Enumerate'}}

  \Procedure{\Enumerate{}}{
    \KwData{A set of tuples $A = \{ (c, \{ M_{1}, \ldots, M_{n}\}) \}$ where $c$ is a \emph{configuration} and $M_{i}$ are maximal matches.}
    \KwOut{The set of all submatches without repetitions.}
    \ForEach{$(c, M) \in A$}{
      $T \leftarrow$ \text{new-root()}
      \ForEach{$M_{i} \in M$}{
        $G \leftarrow \textsc{GroupBy}(M_{i})$\;
        $\textsc{Enumerate'}(T, G, \emptyset, \bot)$\;
        }
    }
  }
  \;
  \Procedure{\Enumeratee{$n, G, S, new$}}{
    \KwData{A node $n$, a set of grouped events $G$, a time-ordered set of events $S$, and a boolean $new$.}
    \Switch{$G$}{
      \uCase{$\emptyset$}{
        \If{$new$}{
          \Return{$S$}
        }
      }
      \uCase{$g \cup G'$}{
        $k \leftarrow c(g.type)$
        $E \leftarrow \binom{g}{k}$
        \ForEach{$e \in E$}{
          \eIf{$\exists n' \in n.children \land n'.event = e$}{
            $\textsc{Enumerate'}(n', G', S \cup e, new)$\;
          }{
            $p \leftarrow$ new-node($e$)\;
            $n.children.add(p)$\;
            \textsc{Enumerate'}$(p, G', S \cup e, \top)$\;
          }
        }
      }
    }
  }
  \;
\caption{Non-repeated enumeration of a set of maximal matches given a predicate configuration.}
\label{algo:enumerate}
\end{algorithm}

\begin{algorithm}[H]
  \DontPrintSemicolon
  \SetAlgoNoEnd % don't print end
  \SetAlgoNoLine % no vertical lines
  \LinesNumbered
  \SetKwProg{Procedure}{procedure}{}{}
  \SetKwFunction{Configurations}{\textsc{Configurations}}

  \Procedure{\Configurations{$M$}}{
    \KwIn{A match $M = \{e_{1}, \ldots, e_{n}\}$ where $e_{i}$ is an event of type $t \in T$.}
    \KwOut{A set $C$ of configurations $c := T \times \mathbb{N}$ where $c$ is the mapping from the event type $t \in T$ to the size of the iteration of the event type $t$ in the submatches of $M$.}
    $V \leftarrow newList$\;
    $e_{0} \cup M' \leftarrow pop(M)$\;
    $A \leftarrow \{ e_{0} \}$\;
    $A.type \leftarrow e_{0}.type$\;
    \For{event $e$ in $M'$}{
      \eIf{$e.type = A.type$}{
        $A \leftarrow A \cup e$\;
        \uIf{$isLast(e)$} {
          $V \leftarrow V + enumFromTo(1, |A|)$
        }
      }{
        $V \leftarrow V + enumFromTo(1, |A|)$\;
        $A \leftarrow \{ e \}$\;
        $A.type \leftarrow e.type$\;
      }
    }
    $WW \leftarrow V_{1} \times \cdots \times V_{n}$\tcp*[l]{$V = \{V_{1}, \cdots, V_{n}\}$}
    $T \leftarrow types(M)$\tcp*[l]{Ordered set of types e.g. $types(A_{1}A_{2}B_{1}C_{1}) = \{A,B,C\}$}
    $C \leftarrow \emptyset$\;
    \ForEach(\tcp*[h]{E.g. $W = \{1, 2, 1\}$}){$W \in WW$}{
      $c \leftarrow \emptyset$\tcp*[l]{E.g. $c = \{(A,1), (B,2), (C, 1)\}$}
      \For{$i \leftarrow 1$ \KwTo $|W|$}{
        $c \leftarrow c \cup (T[i], W[i])$\;
      }
      $C \leftarrow C \cup c$\;
    }
    \Return{C}
  }
\caption{Computes all disjoint configurations of a maximal match.}
\label{algo:configurations}
\end{algorithm}

% You need to make the following observations of "Maximal Matches Enumeration":
% 1. The algorithm produces disjoint submatches given a maximal match.
% 2. The algorithm produces non-disjoint submatches given multiple maximal matches.

% But (2) can be analyzed further:
% 1. Disjoint configurations produce disjoint submatches.
% 2. Non-disjoint configurations produce non-disjoint submatches.

% From previous observations we can conclude that repeated submatches are only generated by applying the same configuration to different maximal matches.

% Uniqueness of submatches is guaranteed by (3) and (4).
% (3) guarantees that the output of each worker is disjoint wrt the others.
% (4) guarantees that the output of a worker is disjoint.

% The complexity of the algorithm remains the same if we accomplish linear time enumeration in each worker (this is the tricky part).

\begin{lemma}[TODO]
  \label{lemma:todo}
  TODO
\end{lemma}

\begin{theorem}[TODO]
  \label{theorem:todo}
  TODO
\end{theorem}

\begin{example}[TODO]
  \label{example:todo}
  TODO
\end{example}

% Soundness and Completness of an Algorithm
%
% Let S be the set of all right answers.
% A sound algorithm never includes a wrong answer in S, but it might miss a few right answers.
% A complete algorithm should get every right answer in S: include the complete set of right answers. But it might include a few wrong answers.
%
% Careful! Soudness and completness in logic has another meaning https://math.stackexchange.com/questions/105575/what-is-the-difference-between-completeness-and-soundness-in-first-order-logic

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \subsection{Distributed tECS enumeration}\label{subsec:distributed_tecs_enumeration}

In this section, we propose \acrfull{dte}, a novel extension of the evaluation algorithm in \cite{core}. In particular, \acrshort{dte} distributes the potentially exponential workload of \textsc{Enumerate} among $n$ asynchronous processes $p_{1}, \ldots, p_{n}$ while preserving the constant time per input event update of the data structure that compactly represents the set of partial matches and the output-linear delay enumeration of the results.

Before giving the formal description of the algorithm, we need to extend the definition of \acrfull{tecs}, as introduced in \cite{core}. A \acrshort{tecs} is a \acrfull{dag} \tecs with two kinds of nodes; union nodes and non-union nodes. Every union node u has exactly two children, the left child left(u) and the right child right(u). Every non-union node n is labelled by a stream position (an element of $\mathcal{N}$) and has at most one child. If non-union node n has no child it is called a \emph{bottom node}, otherwise it is an \emph{output node}. We write pos(n) for the label of non-union node n and next(o) for the unique child of output node o. For a node n, define its \emph{descending-paths}, denoted paths(n), as follows: if n is a bottom node, then paths(n) = 1; if n is an output node, then paths(n) = paths(next(n)); otherwise, paths(n) = paths(left(n)) + paths(right(n)). The descending-paths can be computed in constant.

A \acrshort{tecs} represents sets of \emph{open} complex events. An \emph{open complex event} is a pair $(i, D)$ where $i \in \mathcal{N}$ and $D$ is a finite subset of $\{i, i+1, \ldots\}$. Intuitively, when processing a stream, the open complex events represented by a tECS are partial results that may later become full complex events. Remember that the purpose of constructing \tecs is to be able to enumerate the set \enumCEA at every $j$. To achieve that goal, it will be necessary to enumerate, for certain nodes n in \tecs, the set $\InDoubleBrackets{\text{n}}^{\epsilon}_{\mathcal{E}}(j) := \{ ([i, j], D) | (i, D) \in \InDoubleBrackets{\text{n}}_{\mathcal{E}} \land j - i \leq \epsilon \}$ i.e. all open complex events represented by n that, when closed with j, are within a time window of size $\epsilon$.

Recall that we imposed three restrictions on the structure of a \acrshort{tecs}: (1) it needs to be \emph{time-ordered}, (2) it needs to be \emph{k-bounded}, and (3) its needs to be \emph{duplicate-free}.

\begin{theorem}[{\cite[Theorem 2]{core}}]\label{theorem:theorem2}
Fix k. For every k-bounded and time-ordered tECS \tecs, and for every duplicate-free node n of \tecs, time-window bound $\epsilon$, and position $j$, the set \enumNode can be enumerated with output-linear delay and without duplicates.
\end{theorem}

To ensure that we may enumerate \enumCEA from \tecs by use of Theorem \ref{theorem:theorem2}, \tecs will always be time-orederd, $k$-bounded for $k = 3$, and duplicate-free.

We defined three operations on \tecs: new-bottom($i$), extend(m, $j$) and union($\text{n}_{1},\text{n}_{2}$). The first method, new-bottom($i$) adds a new bottom node b labelled $i$ to \tecs. The second method, extend(n, $j$) adds a new output node o to \tecs with pos(o) = $j$ and next(o) = n. The third method, union($\text{n}_{1},\text{n}_{2}$) returns a node u such that $\InDoubleBrackets{u}_{\mathcal{E}} = \InDoubleBrackets{\text{n}_{1}}_{\mathcal{E}} \cup \InDoubleBrackets{\text{n}_{2}}_{\mathcal{E}}$. Any \acrshort{tecs} that is created using only these three methods is time-ordered and $3$-bounded.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We are ready to description algorithm \acrshort{dte}. An efficient implementation would be execute \cite[Algorithm 1]{core} on a single process e.g. $p_{0}$, and distribute the \acrshort{tecs} \tecs to the rest of the processes $p_{1}, \ldots, p_{n}$, so $p_{0}$ could keep ingesting events at constant time while the rest of processes could be working on the possibly exponential enumeration of \tecs. However, if done in a na\"ive way, distributing the \acrshort{tecs} on each event that triggers a complex event would take time proportional to its size which is at most linear in the length of the stream breaking the constant update time. Hence, the distribution of the tECS has to be done incrementally per input event to preserve the constant time complexity. An algorithm that that incrementally distributes the tECS would need to send to each process all new node added to the tECS at iteration $j$ and additional information on how to add these nodes to the tECS of iteration $j-1$. Furthermore, each process would need to keep an updated hash table, similar to the one used in the evaluation algorithm, in order to apply the incremental changes instructed by the messages from the centralized evaluation process. We argue that this incremental distribution algorithm is \emph{asymptotically equivalent} to executing the update phase from \cite[Algorithm 1]{core} on each process. Both algorithms needs to incrementally update the tECS and the hash table $T$ but the later needs to iterate over all transitions $\Delta$ in the worst-case, however, this takes constant time under data complexity. Consequently, we choose to replicate the update phase of Algorithm 1 on each process and leave for future work a more sophisticated approach.

\newpage

We provide \aref{algo:enumeration} and show that: (1) it enumerates a subset of ${\llbracket \text{n} \rrbracket}^{\epsilon}_{\mathcal{E}}(j)$ of size $\Omega(\frac{{\llbracket \text{n} \rrbracket}^{\epsilon}_{\mathcal{E}}(j))}{|\mathcal{P}|})$, and (2) it does so with output-linear delay after the first complex event. Furthermore, we will show that the union of the enumeration of \aref{algo:enumeration} on each process $p \in \mathcal{P}$ corresponds to ${\llbracket \text{n} \rrbracket}^{\epsilon}_{\mathcal{E}}(j)$.

\begin{algorithm}[H]
  \LinesNumbered
  \DontPrintSemicolon
  \SetAlgoNoEnd % don't print end
  \SetAlgoNoLine % no vertical lines
  \SetKwProg{Procedure}{procedure}{}{}
  \SetKwFunction{Enumerate}{\textsc{Enumerate}}
  \Procedure{\Enumerate{$\mathcal{E}, n, \epsilon, j, p$}}{
    $\delta \leftarrow \lceil \text{paths(n)} \ / \ {|\mathcal{P}|} \rceil$\;
    $\sigma \leftarrow \text{index}(p) \cdot \delta$\;
    st $\leftarrow$ new-stack()\;
    $\tau \leftarrow j - \epsilon $\;
    \If{$\text{max(n)} \ge \tau$}{
      push(st,($n$, $\emptyset$, $\sigma$, $\delta$))\;
    }
    \While{$(n', P, \sigma', \delta') \leftarrow$ pop(st)}{\label{line:enumeration:while:1}
      \While{true}{\label{line:enumeration:while:2}
        \If{$n' \in N_{B}$}{
          output([pos($n'$), $j$], $P$)\;
          \textbf{break}\;
        }
        \ElseIf{$\text{n}' \in N_{O}$}{
          $P \leftarrow P \ \cup $ {pos($n'$)}\;
          $n' \leftarrow $ next($n'$)\;
        }
        \ElseIf{$n' \in N_{U}$}{
          \If{$max(right(n')) \ge \tau$}{
            \eIf{$paths(left(n')) > \sigma'$}{
              $\delta'' \leftarrow \delta' - max(0, paths(left(n')) - \sigma')$\;
            }{
              $\delta'' \leftarrow \delta'$\;
            }
            $\sigma'' \leftarrow max(0, \sigma' - paths(left(n')))$\;
            \If{$paths(right(n')) > \sigma'' \land \delta'' > 0$}{
              push(st, (right($n'$), $P$, $\sigma''$, $\delta''$))\;
            }
          }
          \eIf{$paths(left(n')) > \sigma'$}{\label{line:enumeration:if}
            $n' \leftarrow left(n')$\;
          }{
            \textbf{break}\;
          }
        }
      }
    }
  }
\caption{Ranged enumeration of $\InDoubleBrackets{\text{n}}^{\epsilon}_{\mathcal{E}}(j).$}
\label{algo:enumeration}
\end{algorithm}

\aref{algo:enumeration} uses a stack $st$ with common stack operations: \code{new-stack()} to create an empty stack, \code{push(st, e)} to add an element \code{e} at the top of the stack, and \code{pop(st)} to remove and return the element on the top of the stack. When the stack is empty, we will interpret $e \leftarrow pop(st)$ as \code{false}. We assume that stack operations can be performed in constant time.

Recall that $\mathcal{E}$ encodes the \acrshort{dag} $G_{\mathcal{E}} = (N, E)$ where $N$ are the vertices, and $E$ the edges that go from any union node $u$ to left($u$) and right($u$), and from any output node $o$ to next($o$). For every node $n' \in N$, let ${paths}_{\ge \tau}(n')$ be all paths of $G_{\mathcal{E}}$ that start at $n'$ and end at some bottom node $b$ with $pos(b) \ge \tau$ and let ${paths}_{\ge \tau, \sigma, \delta}$ be at most $\delta$ paths from ${paths}_{\ge \tau}(n')$ starting after path $\pi_{\sigma}$ i.e. the set of paths $\{ \pi_{\sigma}, \pi_{\sigma+1}, \ldots, \pi_{\sigma+\delta}\}$. Intuitively, for every complex event within a time window of size $\epsilon$ there exists exactly one path (as a consequence of $n$ being duplicate-free) that reaches a bottom node $b$ with $pos(b) \ge j - \epsilon$. Formally,

\begin{theorem}\label{theorem:bijection_paths}
There exists a bijection between ${\llbracket \text{n} \rrbracket}^{\epsilon}_{\mathcal{E}}(j)$ and $paths_{\ge j - \epsilon}(n)$.
\end{theorem}

\begin{proof}
$\ldots$
\end{proof}

\aref{algo:enumeration} receives as an input a \acrshort{tecs}, a node $n$, a time-window $\epsilon$, a position $j$, and a process $p$ and traverses $G_{\mathcal{E}}$ in a DFS way and left-to-right order i.e. for every union node $u$, the paths of $left(u)$ are traversed before the ones of the $right(u)$. First, computes the parameters $\sigma, \delta, \tau$ corresponding to the starting and ending path to enumerate and the time-window threshold, respectively. Each iteration of the \code{while} of line~\ref{line:enumeration:while:1} traverses a new path starting from the point it branches from the previous path, except for the first iteration that starts from node $n$. For this, the stack $st$ is used to store the node and partial complex event of that branching point. Then, the \code{while} of line~\ref{line:enumeration:while:2} traverses through the nodes of the next path, following the left direction whenever a union node is reached and adding the right node to the stack whenever need. The \code{if} of line~\ref{line:enumeration:if} makes sure that only $paths_{\ge j - \epsilon, \sigma, \delta}$ are traversed, otherwise, forcing the next branch with \code{break}. Moreover, by checking for every node $n'$ its value $max(n')$ and $paths(right(n'))$ before adding it to the stack, it makes sure of only going through paths in $paths_{\ge j - \epsilon}(n')$ and $paths_{\ge j - \epsilon, \sigma, \delta}$, respectively.

A simpler recursive algorithm could have been used, however, the constant-delay output might not be guaranteed because the number of backtracking steps after branching might be as long as the longest path of $G_{\mathcal{E}}$. To guarantee constant steps after branching and assure constant-delay output, \aref{algo:enumeration} uses a stack which allows to jump immediately to the next branch. We assume that storing $P$ in the stack takes constant time. We materialize this assumption by modelling $P$ as a linked list of positions, where the list is ordered by the last element added. To update $P$ with position $i$, we only need to create a node $i$ that points to the previous last element of $P$. Then, storing $P$ on the stack is just storing the pointer of the last element added.







% HERE
First, we prove that \aref{algo:enumeration} enumerates $paths_{\ge \tau, \sigma, \delta}$ with output-linear delay after $\pi_{\sigma}$, provided that $\mathcal{E}$ is $k$-bounded and time-ordered and $n$ is a duplicate-free node.

\begin{lemma}\label{lemma:enumeration:process}
Fix $k$, $\mathcal{P}$ and $p \in \mathcal{P}$. Let $\mathcal{E}$ be a $k$-bounded and time-ordered \acrshort{tecs}, $n$ a node of $\mathcal{E}$, $\epsilon$ a time-window. Let parameters $\delta, \sigma$ be $\frac{paths_{\ge \tau}(n)}{|\mathcal{P}|}$ and $index(p) \cdot \sigma$, respectively. Then, \aref{algo:enumeration} enumerates $paths_{\ge \tau, \sigma, \delta}$ with output-linear delay after $\pi_{\sigma}$.
\end{lemma}

\begin{proof}
Recall that $paths_{\ge \tau, \sigma, \delta}$ corresponds to the subset $\{ \pi_{\sigma}, \pi_{\sigma+1}, \ldots, \pi_{\sigma+\delta}\} \in paths_{\ge \tau}$ of size $\delta$.

\end{proof}




















Then, we prove using Lemma~\ref{lemma:enumeration:process} that \aref{algo:enumeration} enumerates a subset of ${\llbracket \text{n} \rrbracket}^{\epsilon}_{\mathcal{E}}(j)$ of size $\Omega(\frac{{\llbracket \text{n} \rrbracket}^{\epsilon}_{\mathcal{E}}(j))}{|\mathcal{P}|})$ with output-linear delay after the first complex event, provided that $\mathcal{E}$ is $k$-bounded and time-ordered and $n$ is a duplicate-free node.

\begin{theorem}\label{theorem:enumeration:process}
Fix $k$, $\mathcal{P}$ and $p \in \mathcal{P}$. Let $\mathcal{E}$ be a $k$-bounded and time-ordered \acrshort{tecs}, $n$ a node of $\mathcal{E}$, $\epsilon$ a time-window. Then, \aref{algo:enumeration} enumerates a subset of ${\llbracket \text{n} \rrbracket}^{\epsilon}_{\mathcal{E}}(j)$ of size $\Omega(\frac{{\llbracket \text{n} \rrbracket}^{\epsilon}_{\mathcal{E}}(j))}{|\mathcal{P}|})$ with output-linear delay after the first complex event.
\end{theorem}

\begin{proof}

\end{proof}

\begin{lemma}\label{lemma:paths_equivalence}
If $\sigma = 0$ and $\delta = |{paths}_{\ge \tau}(n')|$, then ${paths}_{\ge \tau, \sigma, \delta}(n') = {paths}_{\ge \tau}(n')$.
\end{lemma}

\begin{proof}

\end{proof}

Let $m = |{paths}_{\ge \tau}(n')| - 1$, $\sigma=0$, and $\delta = |{paths}_{\ge \tau}(n')|$. Then ${paths}_{\ge \tau}(n') = \{\pi_{0}, \pi_{1}, \ldots, \pi_{m}\}$ and by Lemma~\ref{lemma:paths_equivalence} ${paths}_{\ge \tau, \sigma, \delta}(n') = \{\pi_{0}, \pi_{1}, \ldots, \pi_{m}\}$.

Now, we proceed to show that when the enumeration is performed on each process $p \in \mathcal{P}$, the union of the outputs is equivalent to ...

\begin{lemma}
Let $\mathcal{E}$ be a time-ordered \acrshort{tecs}, $n$ a duplicate-free node of $\mathcal{E}$, $\epsilon$ a time-window, $\mathcal{P}$ the set of all processes. Let $P_{p}$ be the output of \aref{algo:enumeration} on process $p \in \mathcal{P}$. Then, $\bigcup\limits_{p \in \mathcal{P}} P_{p} = paths_{\ge \tau}$.
\end{lemma}

\begin{proof}
  We proved by Lemma~\ref{lemma:enumeration:process} that \aref{algo:enumeration} enumerates $paths_{\ge \tau, \sigma, \delta}$ where $\tau$ is fix, and $\sigma and \delta$ are variables that depend on $p$ and $\mathcal{P}$.

  Fix $\delta = \frac{{paths}_{\ge \tau}(n')}{|\mathcal{P}|}$, show that the union of all outputs sets is $\{\pi_{0}, \pi_{1}, \ldots, \pi_{m}\}$. Then, use previous lemmas to show that $\{\pi_{0}, \pi_{1}, \ldots, \pi_{m}\} = {paths}_{\ge \tau, \sigma=0, \delta=|{paths}_{\ge \tau}(n')|}(n')$ and ${paths}_{\ge \tau, \sigma=0, \delta=|{paths}_{\ge \tau}(n')|}(n') = {paths}_{\ge \tau}(n')$.
\end{proof}


Connect with the final theorem...

\begin{theorem}\label{theorem:enumeration}
Let $\mathcal{E}$ be a time-ordered \acrshort{tecs}, $n$ a duplicate-free node of $\mathcal{E}$, $\epsilon$ a time-window, $\mathcal{P}$ the set of all processes. Let $C_{p}$ be the output of \aref{algo:enumeration} on process $p \in \mathcal{P}$. Then, $\bigcup\limits_{p \in \mathcal{P}} C_{p} = {\llbracket \text{n} \rrbracket}^{\epsilon}_{\mathcal{E}}(j)$.
\end{theorem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

% CEA AB+
\begin{figure}[H]
  \centering
  \begin{subfigure}[t]{\textwidth}
    \centering
    \inputtikz{streamAB+}
  \end{subfigure}
  \\
  \begin{subfigure}[b]{\textwidth}
    \begin{minted}[xleftmargin=40pt, linenos=false]{text}
      SELECT *
      FROM S
      WHERE A as a; B + as bb
    \end{minted}
  \end{subfigure}
  \\
  \begin{subfigure}[b]{\textwidth}
    \centering
    \inputtikz{ceaAB+}
  \end{subfigure}
  \caption{A CEA representing $Q_{1}$ from Figure 1 and some of its runs on an example stream.}
  \label{fig:label}
\end{figure}

\begin{figure}[H]
  \centering
  \begin{subfigure}[t]{0.1\linewidth}
    \inputtikz{AB+_0}
  \end{subfigure}
  \begin{subfigure}[t]{0.1\linewidth}
    \inputtikz{AB+_1}
  \end{subfigure}
  \begin{subfigure}[t]{0.24\linewidth}
    \inputtikz{AB+_2}
  \end{subfigure}
  \begin{subfigure}[t]{0.24\linewidth}
    \inputtikz{AB+_3}
  \end{subfigure}
  \begin{subfigure}[t]{0.28\linewidth}
    \inputtikz{AB+_4}
  \end{subfigure}
  \caption{Illustration of Algorithm TODO on the CEA $\mathcal{A}$ and stream $S$ of Figure ???.}
  \label{fig:label}
\end{figure}

\begin{figure}[H]
  \centering
  \begin{subfigure}[t]{0.24\linewidth}
    \inputtikz{AB+_enumeration_0}
  \end{subfigure}
  \begin{subfigure}[t]{0.24\linewidth}
    \inputtikz{AB+_enumeration_1}
  \end{subfigure}
  \begin{subfigure}[t]{0.24\linewidth}
    \inputtikz{AB+_enumeration_2}
  \end{subfigure}
  \begin{subfigure}[t]{0.24\linewidth}
    \inputtikz{AB+_enumeration_3}
  \end{subfigure}
  \caption{Illustration of Algorithm \ref{algo:enumeration} on the CEA $\mathcal{A}$ and stream $S$ of Figure ???.}
  \label{fig:label}
\end{figure}

% CEA A+B+
% \begin{figure}[H]
%   \centering
%   \begin{subfigure}[t]{\textwidth}
%     \centering
%     \inputtikz{streamA+B+}
%   \end{subfigure}
%   \\
%   \begin{subfigure}[b]{\textwidth}
%     \begin{minted}[xleftmargin=40pt, linenos=false]{text}
%       SELECT *
%       FROM S
%       WHERE A + as aa; B + as bb
%     \end{minted}
%   \end{subfigure}
%   \\
%   \begin{subfigure}[b]{\textwidth}
%     \centering
%     \inputtikz{ceaA+B+}
%   \end{subfigure}
%   \caption{A CEA representing $Q_{1}$ from Figure 1 and some of its runs on an example stream.}
%   \label{fig:label}
% \end{figure}

% \begin{figure}[H]
%   \begin{subfigure}[t]{0.1\linewidth}
%     \inputtikz{A+B+_0}
%   \end{subfigure}
%   \begin{subfigure}[t]{0.1\linewidth}
%     \inputtikz{A+B+_1}
%   \end{subfigure}
%   \begin{subfigure}[t]{0.24\linewidth}
%     \inputtikz{A+B+_2}
%   \end{subfigure}
%   \begin{subfigure}[t]{0.24\linewidth}
%     \inputtikz{A+B+_3}
%   \end{subfigure}
%   \begin{subfigure}[t]{0.28\linewidth}
%     \inputtikz{A+B+_4}
%   \end{subfigure}
%   \caption{Illustration of Algorithm 1 on the CEA $\mathcal{A}$ and stream $S$ of Figure ???.}
%   \label{fig:label}
% \end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Chapter summary}

TODO
