\chapter{Introduction}\label{chapter:introduction}

\emph{Complex Event Recognition (CER)} refers to the identification of sets of events that together satisfy some pattern in high-throughput streams of data. This set of events are known as \emph{complex events}. Conceptually, CER systems not only allow to express patterns in terms of the content of the events (like regular stream processing systems), but also in terms of \emph{spatio-temporal constraints}, e.g. the position and the order of the events in the stream. In order to express this spatio-temporal constraints, CER queries include \emph{regular expressions operators} like \emph{unions}, \emph{concatenations} and \emph{kleene stars}.

In recent years, CER has been successfully applied in scenarios like trends on social webs \cite{survey-systems-1}, traffic and transport incidents in smart cities \cite{survey-systems-1}, and real-time analytics \cite{real-time-analytics}. Prominent examples of CER systems from academia and industry include CORE \cite{core}, FlinkCEP \cite{flink-cep}, SASE \cite{sase}, and TESLA \cite{tesla}, among others.  All such systems share the common goal of providing timely reaction to situations of interest in a real-time manner. Thus, having query evaluation mechanisms that minimize latency is a shared desiderata. Nonetheless, the evaluation of CER queries is well-known to be computationally expensive. We illustrate this with the following example.

\begin{example}\label{example:1}
Consider a stream produced by wireless sensors placed in a warehouse, whose main objective is to detect fires. We assume each sensor can measure both temperature (in Celsius degrees) and relative humidity (as a percentage). Additionally, each sensor is assigned a id corresponding to the zone of the warehouse where the sensor is located. The \emph{events} produced by the sensors are composed of the id of the sensor and a measurement corresponding to temperature or relative humidity. We write $T(id, val)$ for an event reporting temperature $val$ from sensor $id$, and $H(id, val)$ for an event reporting humidity $val$ from sensor $id$. An excerpt of the stream of events, indexed by order of arrival, is depicted in Figure~\ref{fig:stream}.

\begin{figure}[H]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c}\hline
    type  &$H$&$T$&$H$&$H$&$T$&$H$&$H$&$T$&$T$ & \ldots \\ \hline
    id  & 1 & 1 & 2 & 1 & 2 & 2 & 1 & 1 & 1 & \multirow{2}{*}{\ldots} \\
    val & 50 & 24& 49& 24& 24& 42& 23& 40& 45\\ \hline
    timestamp & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & \ldots \\ \hline
  \end{tabular}
  \caption{Exemplary stream of events measuring temperature ($T$) and relative humidity ($H$)}
  \label{fig:stream}
\end{figure}

For the sake of illustration, assume that it has been detected that when the temperature of a storage room increases from below 30 celsius degrees to above 40 celsius degrees and the humidity is below 25\% there is a high probability of fire. The following query retrieves the id of the zone where the fire might be originated so the notification system can warn the security team.

\begin{figure}[h!]
  \begin{minted}[xleftmargin=100pt, linenos=false, fontsize=\footnotesize]{text}
    SELECT t2.id FROM warehouse
    WHERE (T as t1; H as h1; T as t2)
    FILTER t1[val < 30] AND h1[val < 25]
      AND t2[val > 40] AND t1[id] = h1[id]
      AND h1[id] = t2[id]
    WITHIN 10 events
  \end{minted}
  \caption{Query on a wireless sensors network stream, which goal is to detect fires.}
  \label{fig:query:1}
\end{figure}

When the query from Figure~\ref{fig:query:1} is applied to the input stream from Figure~\ref{fig:stream}, the resulting complex events are: $\{ 1, 3, 7 \}$, $\{ 1, 6, 7 \}$, $\{ 1, 3, 6, 7 \}$, $\{ 1, 3, 8 \}$, $\{ 1, 6, 8 \}$, $\{ 1, 3, 6, 8 \}$, $\{ 1, 3, 7, 8\}$, $\{ 1, 6, 7, 8\}$, and $\{ 1, 3, 6, 7, 8\}$. Observe that, within a given time window, the number of \emph{partial matches} that consist of a temperature measurement followed by a humidity measurement followed by a temperature measurement may easily be cubic in the number of events in the window. This gets worsened under the default \emph{skip-till-any-match} \cite{skip-till-any-match} policy, where the set of partial matches can grow \emph{exponentially} in the length of the stream.
\end{example}

In order to overcome the issue illustrated by Example~\ref{example:1}, current CER systems apply clever optimizations to compute the set of partial matches (e.g., lazily computing the set of partial matches \cite{core}). Nevertheless, all of these system still suffer from overhead super-linear in the length of the stream, and thus their scalability is limited to queries over short time windows.

An attempt to overcome the detrimental super-linear complexity of contemporary CER systems is the \emph{COmplex event Recognition Engine (CORE)} engine \cite{core}. Such engine builds on top of a \emph{rigorous} and \emph{efficient} framework for CER that leverages the so called \emph{Complex Event Logic} (CEL) \cite{formal-framework-cep, formal-framework-cer}. To do so, it employs a formal language for specifying complex events, called \emph{CEQL}, that contains many features used in the literature including time windows as well as a partition-by event correlation operator \cite{on-the-expressiveness, core}. Such language can be compiled into a \emph{formal computational model} called \emph{Complex Event Automata} (CEA). CORE incorporates an efficient algorithm for evaluating CEA over event streams using constant time, under data complexity, per event followed by output-linear delay enumeration of the complex events, which is not affected by the length of the stream, size of the query, or size of the time window \cite{formal-framework-cer, core}.

One downside of CORE is that its filtering capabilities are limited to unary predicates. \cite{on-the-expressiveness} shows that unary CEL and CEA are expressively equivalent, however, incomparable when equipped with $n$-ary predicates (e.g., equi-joins like \code{t1[id] = h1[id]}). In particular, when CEL is restricted to binary predicates, it is strictly more expressive than CEA. As a result, CORE cannot embed the processing of $n$-ary filtering predicate in the automaton computational model, and thus cannot guarantee optimal performance under non-unary predicates. This only get aggravated in the presence of iteration operators (i.e., the \emph{kleene star}), where the set of partial matches may grow exponentially in the size of the stream, resulting in an exponential cost of enumerating the complex events.

Departing from the discussion and challenges identified above, in this thesis, we embark on the task of giving a new distributed framework for CER that deals with the limitations of many CER system to express and process complex predicates while preserving optimal performance. To that end, we explore how the evaluation of CER queries with $n$-ary filter predicates can be distributed and parallelized. Considering the fact that such kind of complex filter predicates cannot be embedded into the automaton computational model of CORE, we propose to consider them as a post-process after the enumeration phase. Hence, this thesis is focused on studying and proposing different distribution strategies that optimize such phase. We consider, implement and compare multiple distributed architectures, from the processing of complex events in a centralized fashion distributing the filtering predicates to performing the processing of complex events in a distributed fashion as well. All such features are implemented in a novel distributed architecture for CER, namely DCORE (which stands for \emph{Distributed COmplex event Recognition Engine}).

\textbf{Note.} Throughout the development of this thesis, several new publications on the area had been published (e.g., \cite{formal-framework-cer, core}), which impacted the results of this work.

\section{Contributions}\label{sec:contribution}

Our contributions are summarized as follows:

\begin{enumerate}[label=(\roman*)]
  \item We present a distributed framework for CER. This framework circumvents the filtering limitations of CORE while preserving optimal throughput. Based on this framework, we implemented two different architectures: DCERE and DCORE. DCORE uses the novel distributed evaluation algorithm for CER presented in this work.

  \item We present a novel distributed evaluation algorithm for CER. The proposed algorithm tackles (1) the super-linear complexity of non-unary predicates, and (2) the exponential complexity of the enumeration phase. Our work includes a proof of correctness of this algorithm.

  \item We show that our distributed framework is practical. Our experiments show that, in the presence of Big Data requirements, our distributed framework outperforms CORE on processing queries with complex predicates.
\end{enumerate}

\section{Outline}
\label{sec:outline}

The document is organised as follows. We discuss related work in Chapter~\ref{chapter:related_work}. We give an introduction to CEQL and describe how CEQL is compiled into CEA in Chapter~\ref{chapter:preliminaries}. We introduce the distributed CER framework on Chapter~\ref{chapter:distributed-cer}. In Chapter~\ref{chapter:algorithm} we present the novel distributed evaluation algorithm. We dedicate Chapter~\ref{chapter:experimental_evaluation} to the implementation of the framework and the experiments. We present our conclusions and future work on Chapter~\ref{chapter:conclusion}.
